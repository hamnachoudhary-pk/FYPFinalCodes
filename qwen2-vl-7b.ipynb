{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12833537,"sourceType":"datasetVersion","datasetId":8116391}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q transformers accelerate torch torchvision pillow\n\nfrom transformers import AutoTokenizer, AutoModelForVision2Seq\nfrom PIL import Image\nimport torch\n\n# Model name (corrected to a valid vision-language model)\nmodel_name = \"Qwen/Qwen2-VL-7B-Instruct\"  # Updated to correct model name\n\ntry:\n    # Load tokenizer and model\n    tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n    model = AutoModelForVision2Seq.from_pretrained(\n        model_name,\n        torch_dtype=torch.float16,\n        device_map=\"auto\",\n        trust_remote_code=True\n    )\n\n    # Check if CUDA is available, else use CPU\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = model.to(device)\n\n    # Load and preprocess image\n    image_path = \"/kaggle/input/truckairport/atx-cargo-box-airport.jpg\"\n    try:\n        image = Image.open(image_path).convert(\"RGB\")\n    except FileNotFoundError:\n        print(f\"Error: Image file not found at {image_path}\")\n        exit(1)\n\n    # Prepare multimodal input for the model\n    inputs = tokenizer(\n        text=\"Describe this image in detail.\",\n        images=[image],  # Pass the actual image object\n        return_tensors=\"pt\"\n    ).to(device)\n\n    # Generate caption\n    with torch.no_grad():\n        output_ids = model.generate(\n            **inputs,\n            max_new_tokens=200,\n            do_sample=False  # For deterministic output\n        )\n\n    # Decode the generated tokens\n    caption = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n    print(\"Generated Caption:\\n\", caption)\n\nexcept Exception as e:\n    print(f\"An error occurred: {str(e)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}